Компьютерное зрение – одна из главных областей теории искусственных интеллектов, активно
развивающейся последние 50 лет с наибольшим пиком активности последние 10 лет.
Глубинное (глубокое) обучение – раздел теории нейронных сетей, разрабатывающий и исследующий
модели нейронных сетей с большим количеством слоев.
Формально, нейросети решают задачу аппроксимации неизвестной функции. На сегодняшний день все
объяснения эффективности методов обучения нейросетей являются гипотетическими. Часть гипотез
подтверждается многочисленными экспериментами, часть гипотез опровергается, что приводит к
возникновению новых гипотез
Нейронные сети учатся послойно извлекать из изображений информацию, уровень сложности
которой растет с каждым слоем. Например, первый слой запоминает штрихи, перепады цветов и яркости,
второй слой исследует комбинации выходов первого слоя и так далее. Эксперименты показывают, что на
более глубоких слоях производится запоминание таких признаков, как, например, колесо автомобиля, форма
глаз и т.д
Сверточной нейронной сетью называют нейросеть со следующей архитектурой, удобно
визуализируемой в трехмерном пространстве (Рис. 1):
![image](https://user-images.githubusercontent.com/58371161/203812542-82bbb35e-b04a-4e35-b377-a42f507cff95.png)

С математической точки зрения, такая архитектура позволяет уменьшить количество параметров сети,
что позволяет улучшить обобщающие свойства сети. Кроме того, такая архитектура позволяет извлекать
локальные свойства из входных данных.
В качестве входа каждый слой сети принимает трехмерный тензор, на практике чаще всего
являющийся изображением. Таким образом, выходом данного блока будет новое изображение, являющееся
результатом операции, называющейся в графическом редактировании применением фильтра к входу.
Применение фильтра называют сверткой.
Процесс обучения и свертки интерпретируются следующим образом:
1. Фильтры первого запоминают общие свойства, характерные для входных данных.
2. Фильтры последующих слоев запоминают характерные комбинации свойств, полученных
предшествующими слоями
3. С возрастанием глубины слои извлекают все более глубокие связи между свойствами,
характерными для каждого класса входных данных. 
Выходом сверточной сети является большой набор преобразованных данных, содержащих свойства
входного изображения, поэтому после CNN ставятся полносвязные слои, которые производят оценку и интерпретацию извлеченных
свойств, а последний слой выдает вероятности классов.

VGG16 — модель сверточной нейронной сети, предложенная K. Simonyan и A. Zisserman из Оксфордского университета в статье “Very Deep Convolutional Networks for Large-Scale Image Recognition”. Модель достигает точности 92.7% — топ-5, при тестировании на ImageNet в задаче распознавания объектов на изображении.
Архитектура VGG16 представлена на рисунке ниже.

Архитектура нейросети vgg16

На вход слоя conv1 подаются RGB изображения размера 224х224. Далее изображения проходят через стек сверточных слоев, в которых используются фильтры с очень маленьким рецептивным полем размера 3х3.
Пространственное дополнение (padding) входа сверточного слоя выбирается таким образом, чтобы пространственное разрешение сохранялось после свертки, то есть дополнение равно 1 для 3х3 сверточных слоев. Пространственный пулинг осуществляется при помощи пяти max-pooling слоев, которые следуют за одним из сверточных слоев . Операция max-pooling выполняется на окне размера 2х2 пикселей с шагом 2.

После стека сверточных слоев идут три полносвязных слоя: первые два имеют по 4096 каналов, третий — 1000 каналов. Последним идет soft-max слой. Конфигурация полносвязных слоев одна и та же во всех нейросетях.Все скрытые слои снабжены ReLU.



