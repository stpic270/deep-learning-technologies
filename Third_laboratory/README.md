Задача NER от RuREBus [1]
В данной работе были реализованы модели TENER [2] и sbert [3] 

Введение
Распознавание именованных сущностей (NER) — иногда называемое фрагментированием, извлечением или идентификацией сущностей — представляет собой задачу идентификации и категоризации ключевой информации (сущностей) в тексте. Объектом может быть любое слово или ряд слов, которые постоянно относятся к одному и тому же объекту. Каждый обнаруженный объект классифицируется по заранее определенной категории. Например, модель машинного обучения NER может обнаружить слово «super.AI» в тексте и классифицировать его как «Company».

В основе любой модели NER лежит двухэтапный процесс:

1) Обнаружить именованный объект
2) Классифицировать сущность
За этим скрывается несколько вещей. Шаг первый включает в себя обнаружение слова или цепочки слов, образующих сущность. Каждое слово представляет собой токен: «The Great Lakes» — это строка из трех токенов, представляющая одну сущность. Пометка «Inside-outside-beginning» — это распространенный способ указать, где объекты начинаются и заканчиваются.
Второй шаг требует создания категорий сущностей. Вот некоторые распространенные категории сущностей:

Person - Элвис Пресли, Одри Хепберн, Дэвид Бекхэм.
Organization - Google, Mastercard, Оксфордский университет.
Time - 2006, 16:34, 2 часа ночи
Location - Трафальгарская площадь, МоМА, Мачу-Пикчу.
Work of art - «Гамлет», «Герника», «Изгнание на Мейн-стрит».

Алгоритм TENER:

в большинстве моделей NER используется CNN в качестве encoder для символов (рис. 1) В TENER encoder используется не только для извлечения контекстной информации в виде words embedding, но и для кодирования информации на уровне символов в слове, то есть chars embedding

![image](https://user-images.githubusercontent.com/58371161/214795070-7b849570-5f90-4ede-b04c-cefc0c320c4a.png)

(рис. 1) - структура модели TENER для задачи NER [2]

По сравнению с кодировщиком символов на основе BiLSTM [4] CNN более эффективен, его потенциальное преимущество заключается в извлечении различных n-gram и прерывистых шаблонов символов,  например «un..ily» в “unhappily” и “uneasily”.

Дальше по структуре (рис. 1) следует transformer [2]. Авторы статьи заметили, что классическому transformer не хватает направленности по сравнению с моделью BiLSTM, не смотря на то, что transformer имеет position embedding. Поэтому в TENER присутствует изменный вариант учета position embedding и механизма attention, что как заявляют авторы, улучшает направленность, т.к. transformer лучше понимает с какой стороны пришел контекст. Также изменненый transformer благодаря улучшенному механизму внимания лучше сохраняет контекст [2]. Кроме того, авторы убрали масштабирование внимания, что более выгоднее в NER задаче, т.к. на показанных ранее примерах видно, что наибольшую значимость представляют только некоторые слова в предложениия, я вляющиеся сущностями. Формулы изменения механизма atention и position embedding можно найти в статье [2].

Последняя часть TENER - классический модуль CRF, чтобы использовать преимущество зависимости между tags.

Проделланая работа:

В качестве данных были взяты корпуса текса от RuREBus и доразмечены для моделей TENER и sbert. TENER также притерпел некоторые изменения: в качестве words embedding была взята модель navec [5] с размером словаря в 500 000 слов. В качестве chars embedding использовалась библиотека от fastNLP [6] как и в оригинальной модели TENER [7], но с увеличенным пространством embedding и более низким dropout. Также было много других изменений больше связанных с реализацией и запуском TENER, подробно про котороые можно найти в ноутбуке:

Кроме того, на данном тексте была обучена модель sbert [8], взятая с hugging_face [9]. Однако доразметка оказалось довольно неудачной, что существенно снизило количество сущностей для train и test. Финальная выборка получилась следующей 

![image](https://user-images.githubusercontent.com/58371161/214835952-6952f5a0-4a8d-4233-89e6-239b3adc1315.png)

Рис 2 - количество данных

Как можно заметить sbert тестировался на тексте с меньшим количестве слов, которые не имеют заданных сущностей, то есть класса 'O'. Это связано с тем, что возникала некоторая ошибка при тестировании тестового корпуса.

Выводы
Результаты моделей получились следующими:

![image](https://user-images.githubusercontent.com/58371161/214839135-5a2ebfd2-351c-45ab-a722-e6ba8c859db3.png)

Рисунок 3 - результаты на тестовой выборки



