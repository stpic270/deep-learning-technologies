# Задача NER от RuREBus [1]

## Введение
В данной работе были реализованы модели TENER [2] и sbert [3] 
Распознавание именованных сущностей (NER) — иногда называемое фрагментированием, извлечением или идентификацией сущностей — представляет собой задачу идентификации и категоризации ключевой информации (сущностей) в тексте. Объектом может быть любое слово или ряд слов, которые постоянно относятся к одному и тому же объекту. Каждый обнаруженный объект классифицируется по заранее определенной категории. Например, модель машинного обучения NER может обнаружить слово «super.AI» в тексте и классифицировать его как «Company».

В основе любой модели NER лежит двухэтапный процесс:

1) Обнаружить именованный объект
2) Классифицировать сущность
За этим скрывается несколько вещей. Шаг первый включает в себя обнаружение слова или цепочки слов, образующих сущность. Каждое слово представляет собой токен: «The Great Lakes» — это строка из трех токенов, представляющая одну сущность. Пометка «Inside-outside-beginning» — это распространенный способ указать, где объекты начинаются и заканчиваются.
Второй шаг требует создания категорий сущностей. Вот некоторые распространенные категории сущностей:

Person - Элвис Пресли, Одри Хепберн, Дэвид Бекхэм.
Organization - Google, Mastercard, Оксфордский университет.
Time - 2006, 16:34, 2 часа ночи
Location - Трафальгарская площадь, МоМА, Мачу-Пикчу.
Work of art - «Гамлет», «Герника», «Изгнание на Мейн-стрит».

## Алгоритм TENER:

в большинстве моделей NER используется CNN в качестве encoder для символов (рис. 1) В TENER encoder используется не только для извлечения контекстной информации в виде words embedding, но и для кодирования информации на уровне символов в слове, то есть chars embedding

![image](https://user-images.githubusercontent.com/58371161/214795070-7b849570-5f90-4ede-b04c-cefc0c320c4a.png)

(рис. 1) - структура модели TENER для задачи NER [2]

По сравнению с кодировщиком символов на основе BiLSTM [4] CNN более эффективен, его потенциальное преимущество заключается в извлечении различных n-gram и прерывистых шаблонов символов,  например «un..ily» в “unhappily” и “uneasily”.

Дальше по структуре (рис. 1) следует transformer [2]. Авторы статьи заметили, что классическому transformer не хватает направленности по сравнению с моделью BiLSTM, не смотря на то, что transformer имеет position embedding. Поэтому в TENER присутствует изменный вариант учета position embedding и механизма attention, что как заявляют авторы, улучшает направленность, т.к. transformer лучше понимает с какой стороны пришел контекст. Также изменненый transformer благодаря улучшенному механизму внимания лучше сохраняет контекст [2]. Кроме того, авторы убрали масштабирование внимания, что более выгоднее в NER задаче, т.к. на показанных ранее примерах видно, что наибольшую значимость представляют только некоторые слова в предложениия, я вляющиеся сущностями. Формулы изменения механизма atention и position embedding можно найти в статье [2].

Последняя часть TENER - классический модуль CRF, чтобы использовать преимущество зависимости между tags.

## Проделланая работа:

В качестве данных были взяты корпуса текса от RuREBus и доразмечены для моделей TENER и sbert. TENER также притерпел некоторые изменения: в качестве words embedding была взята модель navec [5] с размером словаря в 500 000 слов. В качестве chars embedding использовалась библиотека от fastNLP [6] как и в оригинальной модели TENER [7], но с увеличенным пространством embedding и более низким dropout. Еще вместо оптимизатора SGD был использован классический Adam. Также было много других изменений больше связанных с реализацией и запуском TENER, информацию про котороые можно найти в ноутбуке: Third_laboratory/Разметка_и_использование_TENER.ipynb

Кроме того, на данном тексте была обучена модель sbert [3], взятая с hugging_face [8]. Однако доразметка оказалось довольно неудачной, что существенно снизило количество сущностей для train и test. Финальная выборка получилась следующей 

![image](https://user-images.githubusercontent.com/58371161/214835952-6952f5a0-4a8d-4233-89e6-239b3adc1315.png)

Рис 2 - количество данных

Как можно заметить sbert тестировался на тексте с меньшим количестве слов, которые не имеют заданных сущностей, то есть класса 'O'. Это связано с тем, что возникала некоторая ошибка при тестировании тестового корпуса.

## Выводы
Результаты моделей получились следующими:

![image](https://user-images.githubusercontent.com/58371161/214839135-5a2ebfd2-351c-45ab-a722-e6ba8c859db3.png)

Рисунок 3 - результаты на тестовой выборки

Наличие таких плохих результатов объясняется очень маленьким доразмеченным количеством данных. Тем не менее даже на них видно, что sbert немного дучше чем TENER, что можно объяснить большим вектором words embedding, 1024 против 390 у TENER. Тем не менее за счет модернизированного механизма внимания и объединения words embedding с chars embedding позволили TENER получить неплохие результаты с большой поправкой на неудачный датасет

## Описание ноубуков 

Third_laboratory/Разметка_и_использование_TENER.ipynb - пример разметки текста и его использование с реализацией TENER

Third_laboratory/TENER_full_texts_Adam_Paperspace.ipynb - реализация TENER на готовом тексте, также в конце есть статистика переобучения TENER на 3 текстах

Third_laboratory/RuREBus_sbert.ipynb - реализация sbert на готовом тексте,  в конце есть статистика переобучения sbert на 3 текстах + структура используемой модели

Third_laboratory/RuREBus.py - пример файла для разметки имеющихся данных по hugging face, для работы с ним необходимо в нем изменить _URLS - пути к json файлам


## Список источников:

1) https://github.com/dialogue-evaluation/RuREBus
2) https://arxiv.org/pdf/1911.04474.pdf
3) https://habr.com/ru/company/sberdevices/blog/527576/
4) Lample et al., 2016; Ghaddar and Langlais,2018
5) https://github.com/natasha/navec
6) http://www.fastnlp.top/docs/fastNLP/v0.5.5/fastNLP.html
7) https://github.com/fastnlp/TENER
8) https://huggingface.co/sberbank-ai/sbert_large_nlu_ru

