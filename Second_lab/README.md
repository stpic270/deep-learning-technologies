В данной работе будет реализована классификация видео на основе эмбедингов от VIDEOMAE Model

Теоретическая база 

Эмбединги/векторы признаков — это векторы, представляющие некоторую информацию о некоторой области/задаче, они являются выходными данными из сети или ее промежуточными значениями[2]. Векторизацию данных с помощью ембедингов можно назвать методом уменьшения размерности. Традиционные методы уменьшения размерности — PCA, LDA и т. д. — используют статистические методы для «сжатия» данных, например комбинация линейной алгебры[1]. Современные модели глубокого обучения выполняют уменьшение размерности,  давая представление входных данных, в котором соседние точки соответствуют семантически схожим первоначальных необработанных точкам данных. Например, то, что раньше было одним  вектором, представляющим слово, фразу, изображение и тп., теперь может быть представлено как плотный вектор со значительно меньшей размерностью. Например, если дать модели картинку размерностью 224×224 - получится размерность 50176, что очень много, однако сверточная модель может обработать эти данные и выдать представление изображения как признаки "высокого" уровня с размерностью гораздо меньшей, например 512. Такие данные больше представляют собой структурированный тип и для них уже можно использовать более простые модели.

Чтобы понять что содержат в себе эмбединги рассмотрим пример word-embedding. Их идея состоит в том, чтобы иметь векторы эмбедингов слов, близких по смыслу, чтобы они находились "рядом", но при этом были "далеки" от других слов. "Рядом" и "далеко" означают значение метрики расстояния, например: L2 (евклидово расстояние) или косинусное расстояние. Ключевой момент: каждое число вектора эмбединга соответствует чему-то непосредственно из первичных данных. Данный вектор не обязательно должен быть читаемым для человека, но он должен содержать информацию, с помощью которой более простая модель после эмбедингов может ее понять, например предугадать как близки слова walking-walked и как далеки walking-swam, рис. 1

![image](https://user-images.githubusercontent.com/58371161/209578384-cf321ebe-50e5-475d-b81d-836d320f0960.png)

Рис 1
 





























Источники:
1) https://towardsdatascience.com/understanding-neural-network-embeddings-851e94bc53d2
2) https://medium.com/mlearning-ai/intuition-to-neural-network-embeddings-986c6bcaa502
