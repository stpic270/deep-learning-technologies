{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EQof0pO7PSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a6d72f3-01c8-475f-c359-5ad298772305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import h5py\n",
        "import scipy\n",
        "from sklearn.metrics import f1_score   \n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy import special\n",
        "from matplotlib.pyplot import imshow\n",
        "import cv2\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import keras\n",
        "import gc\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as k\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1gmDarkp2KQ"
      },
      "outputs": [],
      "source": [
        "class adabound():\n",
        "\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), final_lr=0.1, gamma=1e-3,\n",
        "                 eps=1e-8, weight_decay=0, amsbound=False):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "        if not 0.0 <= final_lr:\n",
        "            raise ValueError(\"Invalid final learning rate: {}\".format(final_lr))\n",
        "        if not 0.0 <= gamma < 1.0:\n",
        "            raise ValueError(\"Invalid gamma parameter: {}\".format(gamma))\n",
        "\n",
        "        self.defaults = dict(lr=lr, betas=betas, final_lr=final_lr, gamma=gamma, eps=eps,\n",
        "                        weight_decay=weight_decay, amsbound=amsbound)\n",
        "        \n",
        "        self.param_groups = []\n",
        "\n",
        "        self.param_groups.append(dict(params=params, lr=lr, betas=betas, final_lr=final_lr, \n",
        "                                      gamma=gamma, eps=eps, weight_decay=weight_decay, amsbound=amsbound))\n",
        "\n",
        "        self.base_lrs = list(map(lambda group: group['lr'], self.param_groups))\n",
        "\n",
        "\n",
        "    def initialize_state(self, parameters):\n",
        "\n",
        "        L = len(parameters) # number of layers in the neural networks\n",
        "        self.m = {}\n",
        "        self.v = {}\n",
        "\n",
        "        for l in range(L):\n",
        "\n",
        "            \n",
        "\n",
        "            self.m[\"dw\" + str(l + 1)] = np.zeros_like(parameters[l].weight)\n",
        "            self.m[\"db\" + str(l + 1)] = np.zeros_like(parameters[l].bias)\n",
        "\n",
        "            self.v[\"dw\" + str(l+1)] = np.zeros_like(parameters[l].weight)\n",
        "            self.v[\"db\" + str(l+1)] = np.zeros_like(parameters[l].bias)\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "    def step(self, state=1):\n",
        "\n",
        "        for group, base_lr in zip(self.param_groups, self.base_lrs):\n",
        "            for p, l in zip(group['params'], range(len(group['params']))):\n",
        "                if p.grads is None:\n",
        "                    continue\n",
        "                grad = p.grads\n",
        "                \n",
        "                # State initialization\n",
        "                beta1, beta2 = group['betas']\n",
        "                if state == 1:\n",
        "                  self.initialize_state(self.param_groups[0]['params'])\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                self.m[\"dw\" + str(l + 1)] = beta1 * self.m[\"dw\" + str(l + 1)] + (1 - beta1) * grad['dw']\n",
        "                self.m[\"db\" + str(l + 1)] = beta1 * self.m[\"db\" + str(l + 1)] + (1 - beta1) * grad['db']\n",
        "\n",
        "                self.v[\"dw\" + str(l + 1)] = beta2 * self.v[\"dw\" + str(l + 1)] + (1 - beta2) * np.power(grad['dw'], 2)\n",
        "                self.v[\"db\" + str(l + 1)] = beta2 * self.v[\"db\" + str(l + 1)] + (1 - beta2) * np.power(grad['db'], 2)\n",
        "\n",
        "                \n",
        "                denom_w = np.sqrt(self.v[\"dw\" + str(l + 1)]) + group['eps']\n",
        "                denom_b = np.sqrt(self.v[\"db\" + str(l + 1)]) + group['eps']\n",
        "\n",
        "                bias_correction1 = 1 - beta1 ** state\n",
        "                bias_correction2 = 1 - beta2 ** state\n",
        "                step_size = group['lr'] * np.sqrt(bias_correction2)/ bias_correction1\n",
        "\n",
        "                final_lr = group['final_lr'] * group['lr'] / base_lr\n",
        "                lower_bound = final_lr * (1 - 1 / (group['gamma'] * state + 1))\n",
        "                upper_bound = final_lr * (1 + 1 / (group['gamma'] * state + group['eps']))\n",
        "\n",
        "                step_size_w = np.full_like(denom_w, step_size)\n",
        "                step_size_b = np.full_like(denom_b, step_size)\n",
        "\n",
        "                step_size_w = np.clip(step_size_w / denom_w, lower_bound, upper_bound) * self.m[\"dw\" + str(l + 1)] \n",
        "                step_size_b = np.clip(step_size_b / denom_b, lower_bound, upper_bound) * self.m[\"db\" + str(l + 1)]\n",
        "\n",
        "#               update parameters\n",
        "                p.weight -= step_size_w\n",
        "                p.bias -= step_size_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NplMU8P3p9ZV"
      },
      "outputs": [],
      "source": [
        "class adam():\n",
        "\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, amsbound=False):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "\n",
        "        self.defaults = dict(lr=lr, betas=betas, eps=eps,\n",
        "                        weight_decay=weight_decay, amsbound=amsbound)\n",
        "        \n",
        "        self.param_groups = []\n",
        "\n",
        "        self.param_groups.append(dict(params=params, lr=lr, betas=betas,eps=eps, weight_decay=weight_decay, amsbound=amsbound))\n",
        "\n",
        "        self.base_lrs = list(map(lambda group: group['lr'], self.param_groups))\n",
        "\n",
        "\n",
        "    def initialize_state(self, parameters):\n",
        "\n",
        "        L = len(parameters) # number of layers in the neural networks\n",
        "        self.v = {}\n",
        "        self.s = {}\n",
        "\n",
        "        for l in range(L):\n",
        "\n",
        "            \n",
        "\n",
        "            self.v[\"dw\" + str(l + 1)] = np.zeros_like(parameters[l].weight)\n",
        "            self.v[\"db\" + str(l + 1)] = np.zeros_like(parameters[l].bias)\n",
        "\n",
        "            self.s[\"dw\" + str(l+1)] = np.zeros_like(parameters[l].weight)\n",
        "            self.s[\"db\" + str(l+1)] = np.zeros_like(parameters[l].bias)\n",
        "\n",
        "    \n",
        "    def step(self, state=0):\n",
        "        v_corrected = {}                         # Initializing first moment estimate, python dictionary\n",
        "        s_corrected = {}\n",
        "\n",
        "        for group, base_lr in zip(self.param_groups, self.base_lrs):\n",
        "            for p, l in zip(group['params'], range(len(group['params']))):\n",
        "                if p.grads is None:\n",
        "                    continue\n",
        "                grad = p.grads\n",
        "                \n",
        "                # State initialization\n",
        "                beta1, beta2 = group['betas']\n",
        "                if state == 0:\n",
        "                  self.initialize_state(self.param_groups[0]['params'])\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                self.v[\"dw\" + str(l + 1)] = beta1 * self.v[\"dw\" + str(l + 1)] + (1 - beta1) * grad['dw']\n",
        "                self.v[\"db\" + str(l + 1)] = beta1 * self.v[\"db\" + str(l + 1)] + (1 - beta1) * grad['db']\n",
        "\n",
        "                v_corrected[\"dw\" + str(l + 1)] = self.v[\"dw\" + str(l + 1)] / (1 - np.power(beta1, state+1)+ group['eps'])\n",
        "                v_corrected[\"db\" + str(l + 1)] = self.v[\"db\" + str(l + 1)] / (1 - np.power(beta1, state+1)+ group['eps'])\n",
        "\n",
        "                self.s[\"dw\" + str(l + 1)] = beta2 * self.s[\"dw\" + str(l + 1)] + (1 - beta2) * np.power(grad['dw'], 2)\n",
        "                self.s[\"db\" + str(l + 1)] = beta2 * self.s[\"db\" + str(l + 1)] + (1 - beta2) * np.power(grad['db'], 2)\n",
        "\n",
        "                s_corrected[\"dw\" + str(l + 1)] = self.s[\"dw\" + str(l + 1)] / (1 - np.power(beta2, state+1) + group['eps'])\n",
        "                s_corrected[\"db\" + str(l + 1)] = self.s[\"db\" + str(l + 1)] / (1 - np.power(beta2, state+1) + group['eps'])\n",
        "\n",
        "#               update parameters\n",
        "                p.weight = p.weight - group['lr'] * v_corrected[\"dw\" + str(l + 1)] / np.sqrt(s_corrected[\"dw\" + str(l + 1)] + group['eps'])\n",
        "                p.bias = p.bias - group['lr'] * v_corrected[\"db\" + str(l + 1)] / np.sqrt(s_corrected[\"db\" + str(l + 1)] + group['eps'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-C5VYPMWjlzN"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "def reluDerivative(x):\n",
        "  \n",
        "    x[x<=0] = 0\n",
        "    x[x>0] = 1\n",
        "    return x\n",
        "\n",
        "def zero_pad(x, pad):\n",
        "  \"\"\"\n",
        "  Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
        "  as illustrated in Figure 1.\n",
        "    \n",
        "  Argument:\n",
        "  x -- python numpy array of shape (m, n_h, n_w, n_c) representing a batch of m images\n",
        "  pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
        "    \n",
        "  Returns:\n",
        "  X_pad -- padded image of shape (m, n_h + 2*pad, n_w + 2*pad, n_c)\n",
        "  \"\"\"\n",
        "\n",
        "  x_pad = np.pad(x, ((0, 0), (pad, pad), (pad, pad), (0,0)), mode=\"constant\", constant_values=(0, 0))\n",
        "\n",
        "  return x_pad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fQkJNbuf9Eh"
      },
      "outputs": [],
      "source": [
        "def conv_single_step(a_slice_prev, w, b):\n",
        "\n",
        "  \"\"\"\n",
        "  Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
        "  of the previous layer.\n",
        "    \n",
        "  Arguments:\n",
        "  a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
        "  w -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
        "  b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
        "    \n",
        "  Returns:\n",
        "  z -- a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data\n",
        "  \"\"\"\n",
        "\n",
        "  # Element-wise product between a_slice and w\n",
        "  s = a_slice_prev * w\n",
        "  # Sum over all entries of the volume s\n",
        "  z = np.sum(s)\n",
        "  # Add bias\n",
        "  z = (z + float(b))\n",
        "\n",
        "  return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWcTFYCRjF6u"
      },
      "outputs": [],
      "source": [
        "def pool_forward(a_prev, hparameters, mode=\"max\"):\n",
        "  \"\"\"\n",
        "  Implements the forward pass of the pooling layer\n",
        "    \n",
        "  Arguments:\n",
        "  A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "  hparameters -- python dictionary containing \"f\" and \"stride\"\n",
        "  mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
        "    \n",
        "  Returns:\n",
        "  A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
        "  cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
        "  \"\"\"\n",
        "  # Retrieve dimensions from the input shape\n",
        "  m, n_h_prev, n_w_prev, n_c_prev = a_prev.shape\n",
        "\n",
        "  stride = hparameters['stride']\n",
        "  f = hparameters['f']\n",
        "\n",
        "  # Define the dimensions of the output\n",
        "  n_h = int((n_h_prev - f)/stride) + 1\n",
        "  n_w = int((n_w_prev - f)/stride) + 1\n",
        "  n_c = n_c_prev\n",
        "\n",
        "  # Creating the output matrix a\n",
        "  a = np.zeros((m, n_h, n_w, n_c))\n",
        "\n",
        "  # for loop  through all of m conv channels\n",
        "  for i in range(m):\n",
        "\n",
        "    # for loop  through all of height next pooled conv channels\n",
        "    for heigh in range(n_h):\n",
        "      # Forming the vertical shape of the next window \n",
        "      vert_start = heigh * stride\n",
        "      vert_end = heigh * stride + f\n",
        "\n",
        "      # for loop  through all of width next pooled conv channels\n",
        "      for wid in range(n_w):\n",
        "\n",
        "        # Forming the horizontal shape of the next window \n",
        "        horiz_start = wid * stride\n",
        "        horiz_end = wid * stride + f\n",
        "\n",
        "        # for loop  through all of amount of conv channels\n",
        "        for chan in range(n_c):\n",
        "          # Defining the current slice on the mth training example of a_prev\n",
        "          a_slice_prev = a_prev[i, vert_start:vert_end, horiz_start:horiz_end, chan]\n",
        "\n",
        "          ## Compute the pooling operation on the slice\n",
        "          if mode == \"max\":\n",
        "            a[i, heigh, wid, chan] = np.max(a_slice_prev)\n",
        "          elif mode == \"average\":\n",
        "            a[i, heigh, wid, chan] = np.mean(a_slice_prev)\n",
        "  cache = (a_prev, hparameters)\n",
        "\n",
        "  return a, cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RAmtjTEvlMX"
      },
      "outputs": [],
      "source": [
        "def create_mask_from_window(x):\n",
        "    \"\"\"\n",
        "    Creates a mask from an input matrix x, to identify the max entry of x.\n",
        "    \n",
        "    Arguments:\n",
        "    x -- Array of shape (f, f)\n",
        "    \n",
        "    Returns:\n",
        "    mask -- Array of the same shape as window, contains a True at the position corresponding to the max entry of x.\n",
        "    \"\"\"\n",
        "    \n",
        "    mask = x == np.max(x)\n",
        "    \n",
        "    return mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-dDc3inwL_h"
      },
      "outputs": [],
      "source": [
        "def distribute_value(dz, shape):\n",
        "\n",
        "  \"\"\"\n",
        "  Distributes the input value in the matrix of dimension shape\n",
        "    \n",
        "  Arguments:\n",
        "  dz -- input scalar\n",
        "  shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz\n",
        "    \n",
        "  Returns:\n",
        "  a -- Array of size (n_H, n_W) for which we distributed the value of dz\n",
        "  \"\"\"\n",
        "\n",
        "    # Retrieve dimensions from shape (≈1 line)\n",
        "    (n_H, n_W) = shape\n",
        "    \n",
        "    # Calculate the value to distribute on the matrix (≈1 line)\n",
        "    average = dz / (n_H * n_W)\n",
        "    \n",
        "    # Create a matrix where every entry is the \"average\" value (≈1 line)\n",
        "    a = np.ones(shape) * average\n",
        "    \n",
        "  return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eu79z5M-wTW5"
      },
      "outputs": [],
      "source": [
        "def pool_backward(da, cache, mode = \"max\"):\n",
        "\n",
        "  \"\"\"\n",
        "  Implements the backward pass of the pooling layer\n",
        "    \n",
        "  Arguments:\n",
        "  da -- gradient of cost with respect to the output of the pooling layer, same shape as A\n",
        "  cache -- cache output from the forward pass of the pooling layer, contains the layer's input and hparameters \n",
        "  mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
        "    \n",
        "  Returns:\n",
        "  da_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev\n",
        "  \"\"\"\n",
        "  # Unpacking the cache\n",
        "  a_prev, hparameters = cache\n",
        "\n",
        "  stride = hparameters['stride']\n",
        "  f = hparameters['f']\n",
        "\n",
        "  # Unpacking the dimensions for later forming of pooled conv derivative shape\n",
        "  m, n_h_prev, n_w_prev, n_c_prev = a_prev.shape\n",
        "  m, n_h, n_w, n_c = da.shape\n",
        "\n",
        "  # Forming da_prev with zeros\n",
        "  da_prev = np.zeros((m, n_h_prev, n_w_prev, n_c_prev))\n",
        "\n",
        "  # for loop with through all of m conv channels\n",
        "  for i in range(m):\n",
        "    da_prev_slice = da_prev[i]\n",
        "\n",
        "    # for loop  through all of height unpooled conv channels\n",
        "    for heigh in range(n_h):\n",
        "\n",
        "      # for loop through all of width unpooled conv channels\n",
        "      for wid in range(n_w):\n",
        "\n",
        "        # for loop  through all of amount of unpooled conv channels\n",
        "        for chan in range(n_c):\n",
        "\n",
        "          # Forming the vertical and horizontal shape of the next window \n",
        "          vert_start = heigh * stride\n",
        "          vert_end = heigh * stride + f\n",
        "          horiz_start = wid * stride\n",
        "          horiz_end = wid * stride + f\n",
        "\n",
        "          if mode == 'max':\n",
        "            # a_slice_prev - a window for calculation of pooled conv map\n",
        "            a_slice = da_prev_slice[vert_start:vert_end, horiz_start:horiz_end, chan]\n",
        "            # create_mask\n",
        "            mask = create_mask_from_window(a_slice)\n",
        "            # Set da_prev to be da_prev + (the mask multiplied by the correct entry of da)\n",
        "            da_prev[i, vert_start:vert_end, horiz_start:horiz_end, chan] += mask * da[i, heigh, wid, chan]\n",
        "\n",
        "          if mode == 'average':\n",
        "            # Define the shape of the filter as fxf\n",
        "            shape = (f, f)\n",
        "            # Get the value a from da\n",
        "            da_slice = da[i, heigh, wid, chan]\n",
        "            # Distribute it to get the correct slice of da_prev. i.e. Add the distributed value of da.\n",
        "            da_prev[i, vert_start:vert_end, horiz_start:horiz_end, chan] += distribute_value(da_slice, shape)\n",
        "\n",
        "\n",
        "  return da_prev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_frfh2Pi1O9T"
      },
      "outputs": [],
      "source": [
        "class conv2d:\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=0, pooling=False):\n",
        "        \"\"\"\n",
        "        param in_channels: the number of channels of the input data\n",
        "        param out_channels: the number of channels of the output(aka the number of filters applied in the layer)\n",
        "        param kernel_size: the specified size of the kernel(both height and width)\n",
        "        param stride: the stride of convolution\n",
        "        param padding: the size of padding. Pad zeros to the input with padding size.\n",
        "        \"\"\"\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.cache = None\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        self.weight = 1e-3 * np.random.randn(self.kernel_size, self.kernel_size, self.in_channels, self.out_channels)\n",
        "        self.bias = np.zeros((1, 1, 1, self.out_channels))\n",
        "\n",
        "    def conv_forward(self, x, activation='relu'):\n",
        "\n",
        "        \n",
        "        # x: a conv_map from previous conv_forward\n",
        "        \n",
        "\n",
        "        # Unpacking the dimensions for later forming of new conv map shape\n",
        "        a_prev = x\n",
        "        m, n_h_prev, n_w_prev, n_c_prev = x.shape\n",
        "        f, f, n_c_prev, n_c = w.shape\n",
        "\n",
        "        w = self.weight\n",
        "        b = self.bias\n",
        "\n",
        "        stride = self.stride\n",
        "        pad = self.padding\n",
        "\n",
        "        # The calculations of new shape dimensions\n",
        "        n_h = int((n_h_prev + 2*pad - f)/stride) + 1\n",
        "        n_w = int((n_w_prev + 2*pad - f)/stride) + 1\n",
        "\n",
        "        # z: matrix with new shape - results of convolution operation\n",
        "        # a: new conv map - after activation the z matrix\n",
        "        z = np.zeros((m, n_h, n_w, n_c))\n",
        "        a = np.zeros((m, n_h, n_w, n_c))\n",
        "        \n",
        "        # Padding the input conv map\n",
        "        a_prev_pad = zero_pad(a_prev, pad)\n",
        "\n",
        "        # for loop through all of m channels\n",
        "        for i in range(m):\n",
        "          # Extract the mth example of previous conv map with padding\n",
        "          a_prev_pad_m = a_prev_pad[i]\n",
        "\n",
        "          # for loop through all of height image channels\n",
        "          for heigh in range(n_h):\n",
        "            # Forming the vertical shape of the next window \n",
        "            vert_start = heigh * stride\n",
        "            vert_end = heigh * stride + f\n",
        "\n",
        "            # for loop through all of width image channels\n",
        "            for wid in range(n_w):\n",
        "              # Forming the horizontal shape of the next window \n",
        "              horiz_start = wid * stride \n",
        "              horiz_end = wid * stride + f\n",
        "              # for loop through all of amount of conv image out_channels\n",
        "              for chan in range(n_c):\n",
        "                # a_slice_prev - a window for calculation of new conv map, it has the same dimension as weights\n",
        "                a_slice_prev = a_prev_pad_m[vert_start: vert_end, horiz_start: horiz_end, :]\n",
        "                weights = w[:,:,:, chan]\n",
        "                biases = b[:, :, :, chan]\n",
        "                # Calculation the (3D) slice with the correct filter weights and biases, to get back one output neuron.\n",
        "                z_slice = z[i, heigh, wid, chan] = conv_single_step(a_slice_prev, weights, biases)\n",
        "\n",
        "                if activation == 'relu':\n",
        "                  a[i, heigh, wid, chan] = relu(z_slice)\n",
        "\n",
        "        # Making sure your output shape is correct\n",
        "        assert(z.shape == (m, n_h, n_w, n_c))\n",
        "        # Pooling new conv map if necessary\n",
        "        if self.pooling == True:\n",
        "            a, self.pool_cache = pool_forward(a, hparameters=dict(f=2, stride=2))\n",
        "            \n",
        "\n",
        "        self.cache = (a_prev, z)\n",
        "\n",
        "\n",
        "\n",
        "        return a\n",
        "\n",
        "    def backward(self, da):\n",
        "\n",
        "        # da - gradient input that came from previous conv.backward during backpropagation\n",
        "\n",
        "        # Pool backward for da, if this conv2d did pooling during the forward operation\n",
        "        if self.pooling == True:\n",
        "            da = pool_backward(da, self.pool_cache)\n",
        "\n",
        "        \n",
        "        stride = self.stride\n",
        "        pad = self.padding\n",
        "\n",
        "        w = self.weight\n",
        "        b = self.bias\n",
        "        \n",
        "        # Unpacking cache and dz calculation \n",
        "        (a_prev, z) = self.cache\n",
        "        dz = reluDerivative(z) * da\n",
        "\n",
        "        # Unpacking the dimensions for later forming of new conv map shape\n",
        "        m, n_h_prev, n_w_prev, n_c_prev = a_prev.shape\n",
        "        f, f, n_c_prev, n_c = w.shape\n",
        "        m, n_h, n_w, c = dz.shape               \n",
        "\n",
        "        # Forming dw and db for this conv and da_prev for calculation of dz in the next conv.backward\n",
        "        da_prev = np.zeros((m, n_h_prev, n_w_prev, n_c_prev))\n",
        "        dw = np.zeros((f, f, n_c_prev, n_c))\n",
        "        db = np.zeros((1, 1, 1, n_c))\n",
        "\n",
        "        # Padding previous conv map and derivative \n",
        "        a_prev_pad = zero_pad(a_prev, pad)\n",
        "        da_prev_pad = zero_pad(da_prev, pad)\n",
        "\n",
        "        # for loop with through all of m channels\n",
        "        for i in range(m):\n",
        "\n",
        "          # Extract the mth examples of previous conv map and derivative with padding\n",
        "          a_prev_pad_m = a_prev_pad[i]\n",
        "          da_prev_pad_m = da_prev_pad[i]\n",
        "\n",
        "          # for loop through all of height image channels\n",
        "          for heigh in range(n_h):\n",
        "\n",
        "            # for loop  through all of width image channels\n",
        "            for wid in range(n_w):\n",
        "\n",
        "              # for loop through all of amount of conv image out_channels\n",
        "              for chan in range(n_c):\n",
        "\n",
        "                # Forming the vertical and horizontal shape of the next window \n",
        "                vert_start = heigh * stride\n",
        "                vert_end = heigh * stride + f\n",
        "                horiz_start = wid * stride\n",
        "                horiz_end = wid * stride + f\n",
        "\n",
        "                # a_slice - a window of previous layer for calculation of derivative (dw)\n",
        "                a_slice = a_prev_pad_m[vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "\n",
        "                # Calculations of dericatives\n",
        "                da_prev_pad_m[vert_start:vert_end, horiz_start:horiz_end, :] += w[:, :, :, chan] * dz[i, heigh, wid, chan]\n",
        "                dw[:, :, :, chan] += a_slice * dz[i, heigh, wid, chan]\n",
        "                db[:, :, :, chan] += dz[i, heigh, wid, chan]\n",
        "\n",
        "          # Set the ith training example's da_prev to the unpaded da_prev_pad_m\n",
        "          da_prev[i] = da_prev_pad_m[pad:-pad, pad:-pad, :]\n",
        "        \n",
        "        # Calculate mean over m examples\n",
        "        dw /= m\n",
        "        db /= m\n",
        "\n",
        "        grads = dict(da_prev=da_prev, dw=dw, db=db)\n",
        "        self.grads = grads\n",
        "        return grads\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLPqHj3Pnlqb"
      },
      "outputs": [],
      "source": [
        "class linear():   \n",
        "\n",
        "  def __init__(self, in_n, out_n, activation='relu'):\n",
        "\n",
        "    self.in_n = in_n\n",
        "    self.out_n = out_n\n",
        "    self.activation = activation\n",
        "    self.eps = 0.000001\n",
        "    self.initialize_parameters_deep([in_n, out_n])\n",
        "\n",
        "  def initialize_parameters_deep(self, layer_dims):\n",
        "  \n",
        "    \n",
        "    L = len(layer_dims)\n",
        "\n",
        "    for l in range(1, L):\n",
        "      self.weight = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
        "      self.bias = np.zeros((layer_dims[l], 1))\n",
        "\n",
        "\n",
        "  def linear_forward(self, a, w, b):\n",
        "\n",
        "    z = np.dot(w, a) + b\n",
        "    cache = a, w, b\n",
        "\n",
        "    return z, cache\n",
        "\n",
        "  def linear_activation_forward(self, a_prev, w, b, activation):\n",
        "\n",
        "    if activation == \"relu\":\n",
        "      z, linear_cache = self.linear_forward(a_prev, w, b)\n",
        "      a, activation_cache = self.relu(z)\n",
        "\n",
        "    if activation == \"sigmoid\":\n",
        "      z, linear_cache = self.linear_forward(a_prev, w, b)\n",
        "      a, activation_cache = self.sigmoid(z)\n",
        "\n",
        "    if activation =='softmax':\n",
        "      z, linear_cache = self.linear_forward(a_prev, w, b)\n",
        "      a, activation_cache = self.softmax(z)\n",
        "\n",
        "    cache = (linear_cache, activation_cache)\n",
        "    return a, cache\n",
        "\n",
        "  def l_linear_forward(self, x):\n",
        "\n",
        "    a = x\n",
        "    self.caches = []\n",
        "    \n",
        "    \n",
        "\n",
        "    AL, cache = self.linear_activation_forward(a, self.weight, self.bias, activation=self.activation)\n",
        "    self.caches.append(cache)\n",
        "\n",
        "    return AL\n",
        "\n",
        "  def compute_cost(self, AL, Y):\n",
        "    \n",
        "    AL = (AL==0) * self.eps + AL\n",
        "    Y = Y.reshape(AL.shape)\n",
        "    loss=-np.sum(Y*np.log(AL))\n",
        "    self.dAL = AL - Y\n",
        "\n",
        "    return loss/float(AL.shape[1])\n",
        "    \n",
        "\n",
        "  def linear_backward(self, dz, cache):\n",
        "\n",
        "    a_prev, w, b = cache\n",
        "    m = a_prev.shape[1]\n",
        "    dw = 1/m * np.dot(dz, a_prev.T)\n",
        "    db = 1/m * np.sum(dz, axis = 1, keepdims =True)\n",
        "    dA_prev = np.dot(w.T, dz)\n",
        "\n",
        "    return dA_prev, dw, db\n",
        "\n",
        "  def linear_activation_backward(self, da, cache, activation):\n",
        "\n",
        "    linear_cache, activation_cache = cache\n",
        "\n",
        "    if self.activation == \"relu\":\n",
        "      dz = self.relu_backward(da, activation_cache)\n",
        "      da_prev, dw, db = self.linear_backward(dz, linear_cache)\n",
        "\n",
        "    if self.activation == \"sigmoid\":\n",
        "      dz = self.sigmoid_backward(da, activation_cache)\n",
        "      da_prev, dw, db = self.linear_backward(dz, linear_cache)\n",
        "\n",
        "    if self.activation == \"softmax\":\n",
        "      dz = da\n",
        "      da_prev, dw, db = self.linear_backward(dz, linear_cache)\n",
        "\n",
        "    return da_prev, dw, db\n",
        "\n",
        "  def backward(self, da_prev=0.5):\n",
        "\n",
        "    grads = {}\n",
        "    L = len(self.caches) \n",
        "    if self.activation == 'softmax':\n",
        "      dAL = self.dAL\n",
        "    else:\n",
        "      dAL = da_prev\n",
        "\n",
        "    current_cache = self.linear_activation_backward(dAL, self.caches[L-1], activation=self.activation)\n",
        "    d_aprev_temp, dw_temp, db_temp = current_cache\n",
        "    grads[\"da_prev\"] = d_aprev_temp\n",
        "    grads[\"dw\"] = dw_temp\n",
        "    grads[\"db\"] = db_temp\n",
        "\n",
        "\n",
        "    self.grads = grads\n",
        "    return grads\n",
        "\n",
        "          \n",
        "    return parameters\n",
        "\n",
        "  def softmax(self, z):\n",
        "\n",
        "    a = special.softmax(z)\n",
        "    a = np.clip(a, self.eps, 1)\n",
        "\n",
        "    return a, z\n",
        "\n",
        "\n",
        "  def relu(self, z):\n",
        "\n",
        "    a = z * (z > 0)\n",
        "\n",
        "    return a, z\n",
        "\n",
        "  def relu_backward(self, da, z):\n",
        "\n",
        "    g = 1 * (z > 0)\n",
        "    dz = np.multiply(g, da)\n",
        "\n",
        "    return dz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrteA5VRPPL0"
      },
      "outputs": [],
      "source": [
        "class vgg16():\n",
        "    def __init__(self, num_classes=10, shrink=7):\n",
        "\n",
        "        self.layer1 = conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer2 = conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, pooling=True)\n",
        "        self.layer3 = conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer4 = conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, pooling=True)\n",
        "        self.layer5 = conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer6 = conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer7 = conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, pooling=True)\n",
        "        self.layer8 = conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer9 = conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer10 = conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1, pooling=True)\n",
        "        self.layer11 = conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer12 = conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer13 = conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1, pooling=True)\n",
        "        self.lnn1 = linear(shrink*shrink*512, 4096)\n",
        "        self.lnn2 = linear(4096, 4096)\n",
        "        self.lnn3 = linear(4096, num_classes, activation='softmax')\n",
        "\n",
        "        \n",
        "    def forward(self, x, batch_size=1):\n",
        "        out = self.layer1.conv_forward(x)\n",
        "        out = self.layer2.conv_forward(out)\n",
        "        #print(out.shape)\n",
        "        out = self.layer3.conv_forward(out)\n",
        "        out = self.layer4.conv_forward(out)\n",
        "        #print(out.shape)\n",
        "        out = self.layer5.conv_forward(out)\n",
        "        out = self.layer6.conv_forward(out)\n",
        "        out = self.layer7.conv_forward(out)\n",
        "       # print(out.shape)\n",
        "        out = self.layer8.conv_forward(out)\n",
        "        out = self.layer9.conv_forward(out)\n",
        "        out = self.layer10.conv_forward(out)\n",
        "       # print(out.shape)\n",
        "        out = self.layer11.conv_forward(out)\n",
        "        out = self.layer12.conv_forward(out)\n",
        "        out = self.layer13.conv_forward(out)\n",
        "       # print(out.shape)\n",
        "        out = out.reshape(-1, batch_size)\n",
        "        #print(out.shape)\n",
        "        out = self.lnn1.l_linear_forward(out)\n",
        "        out = self.lnn2.l_linear_forward(out)\n",
        "        out = self.lnn3.l_linear_forward(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, layers, batch_size=1):\n",
        "\n",
        "      self.GR = []\n",
        "      grads = self.lnn3.backward()\n",
        "      self.GR.append(grads)\n",
        "\n",
        "      for l in layers[0:2]: \n",
        "        grads = l.backward(grads['da_prev'])\n",
        "        self.GR.append(grads)\n",
        "      a_prev = self.layer13.cache[0]\n",
        "      dim = int(a_prev.shape[1] / 2)\n",
        "      grads['da_prev'] = grads['da_prev'].reshape(batch_size, dim, dim, 512)\n",
        "      for l in layers[2:]: \n",
        "        grads = l.backward(grads['da_prev'])\n",
        "        self.GR.append(grads)\n",
        "\n",
        "      GR = self.GR\n",
        "\n",
        "      return GR\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6v76z7_v0z3"
      },
      "outputs": [],
      "source": [
        "def sp_prop(model):\n",
        "\n",
        "  spisok = []\n",
        "  spisok_l = []\n",
        "\n",
        "  for l in model.__dict__.keys():\n",
        "    spisok.append(model.__dict__[l])\n",
        "\n",
        "  for l in reversed(spisok):\n",
        "    spisok_l.append(l)\n",
        "  \n",
        "  return spisok_l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3FkNsC2VD_m"
      },
      "outputs": [],
      "source": [
        "x= np.random.randn(2, 32, 32, 1)\n",
        "batch_size = x.shape[0]\n",
        "model = vgg16(num_classes=10, shrink=x.shape[1]//32)\n",
        "params = sp_prop(model)\n",
        "params.reverse()\n",
        "opt = adabound(params=params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cC31IV-JJd5N"
      },
      "outputs": [],
      "source": [
        "AA = model.forward(x, batch_size)\n",
        "loss = model.lnn3.compute_cost(AA, np.array(np.eye(20)[1]).reshape(-1, 2))\n",
        "layers = sp_prop(model)\n",
        "grads = model.backward(layers[1:], x.shape[0])\n",
        "opt.step(state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnp7tmyzGqHO",
        "outputId": "61eb59fe-1ea5-4e85-d60f-ef1d3f0aa9e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from matplotlib import pyplot\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "Ry1jRWmUn77L",
        "outputId": "fd46e759-7c9d-4e10-dacc-9d09bc110966"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "for i in range(3):  \n",
        "  pyplot.subplot(330 + 1 + i)\n",
        "  pyplot.imshow(x_train[i], cmap=pyplot.get_cmap('gray'))\n",
        "  pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4XCCuOgoNik"
      },
      "outputs": [],
      "source": [
        "# expand new axis, channel axis \n",
        "x_train, x_test = np.expand_dims(x_train, axis=-1), np.expand_dims(x_test, axis=-1)\n",
        "# it's always better to normalize \n",
        "x_train, x_test = x_train.astype('float32') / 255.0, x_test.astype('float32') / 255.0\n",
        "# resize the input shape , i.e. old shape: 28, new shape: 32\n",
        "x_train, x_test = tf.image.resize(x_train, [32,32]), tf.image.resize(x_test, [32,32]) # if we want to resize \n",
        "# one-hot \n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPZ5JBJdoQjv",
        "outputId": "596899cc-60c0-4562-fa46-9c343f1906fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([60000, 32, 32, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beTfqCdYoTqJ",
        "outputId": "2b800378-8025-40db-94f2-74fe4bfff2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 32, 32, 1) (60000, 10)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSCEVnmcoVkH"
      },
      "outputs": [],
      "source": [
        "# Batch_size\n",
        "X_train, Y_train, X_val, Y_val = [], [], [], []\n",
        "batch_size = 3\n",
        "for i in range(0, 60, batch_size):\n",
        "  start_idx, end_idx = i, i + batch_size\n",
        "  X_train.append(x_train[start_idx:end_idx])\n",
        "  Y_train.append(y_train[start_idx:end_idx].reshape(10, batch_size))\n",
        "\n",
        "for i in range(0, 10, batch_size):\n",
        "  start_idx, end_idx = i, i + batch_size\n",
        "  X_val.append(x_test[start_idx:end_idx])\n",
        "  Y_val.append(y_test[start_idx:end_idx].reshape(10, batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM6FcOE-o7Er",
        "outputId": "5831ab59-1ad2-477f-8de8-d1e9c76bb3d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3, 32, 32, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "X_val[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V58v9Ze4tuz-"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "for i in range(10):\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNgRlu_G2R2j",
        "outputId": "a9b9bf25-32d2-4473-b9a4-737ceca5f51a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shrink =  1 batch_size =  3\n",
            "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "[[0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
            "  0.03333333 0.03333333 0.03333333 0.03333333]\n",
            " [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
            "  0.03333333 0.03333333 0.03333333 0.03333333]\n",
            " [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
            "  0.03333333 0.03333333 0.03333333 0.03333333]]\n",
            "loss =  3.4011973816621555\n",
            "f1_macro =  0.0\n",
            "accuracy =  0.0\n",
            "[[0.03323049 0.03322954 0.03323143 0.03354649 0.03355015 0.03354591\n",
            "  0.03327254 0.03327453 0.03327447 0.033234  ]\n",
            " [0.03323545 0.03323453 0.03322107 0.0332214  0.0332219  0.03324247\n",
            "  0.03324256 0.03324327 0.03355729 0.03356094]\n",
            " [0.03355607 0.03324626 0.03324662 0.03324696 0.03353294 0.03353692\n",
            "  0.03353247 0.03324407 0.03324394 0.03324331]]\n",
            "loss =  3.3947382295212556\n",
            "f1_macro =  0.5\n",
            "accuracy =  0.6666666666666666\n",
            "[[0.03302975 0.03302363 0.03302944 0.0339773  0.03399923 0.03397476\n",
            "  0.03310955 0.03311257 0.03311395 0.03303257]\n",
            " [0.03302963 0.03303115 0.03303246 0.03303086 0.03303311 0.03306398\n",
            "  0.03306272 0.03306712 0.03397912 0.03400396]\n",
            " [0.03397638 0.03305637 0.03305657 0.03305737 0.0339651  0.03398938\n",
            "  0.0339642  0.03306688 0.03306497 0.03306592]]\n",
            "loss =  3.381467596010347\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n",
            "[[0.03272928 0.03270431 0.03272954 0.0346216  0.03470855 0.0346151\n",
            "  0.03286717 0.03286137 0.03287503 0.03272961]\n",
            " [0.03270876 0.03272993 0.03274304 0.03272516 0.03274422 0.03279954\n",
            "  0.03278721 0.03280589 0.03462007 0.03470639]\n",
            " [0.03461127 0.03278123 0.03276824 0.0327852  0.03458763 0.03467494\n",
            "  0.03458474 0.03280252 0.03278921 0.03280328]]\n",
            "loss =  3.361112972944362\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n",
            "[[0.03225371 0.03215166 0.03225726 0.03565477 0.03598069 0.03563822\n",
            "  0.03247234 0.03241259 0.03248582 0.0322421 ]\n",
            " [0.03214122 0.03224435 0.03228058 0.03218782 0.03228176 0.03236338\n",
            "  0.03228708 0.03237615 0.03564126 0.03596467]\n",
            " [0.03562367 0.03233828 0.03225866 0.03234303 0.03558611 0.03590438\n",
            "  0.0355752  0.03237601 0.0322982  0.03237904]]\n",
            "loss =  3.3256290253287966\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n",
            "[[0.03141012 0.03104461 0.03142319 0.03749114 0.03864369 0.03744531\n",
            "  0.03175639 0.03149345 0.03178247 0.03136823]\n",
            " [0.03098991 0.03137946 0.03144535 0.03108745 0.03144912 0.03157743\n",
            "  0.03126708 0.03160212 0.03744257 0.03858311]\n",
            " [0.03740019 0.0315349  0.03121324 0.03154693 0.03734635 0.03846746\n",
            "  0.03731463 0.03159787 0.03128913 0.0316071 ]]\n",
            "loss =  3.2554183358478928\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n",
            "[[0.029694   0.02855542 0.02972047 0.04110151 0.04504516 0.04099296\n",
            "  0.03024154 0.02933009 0.03028545 0.02959897]\n",
            " [0.02841352 0.02962588 0.02972102 0.02857902 0.02973878 0.02995005\n",
            "  0.02892449 0.02999394 0.04100619 0.04490087]\n",
            " [0.04090589 0.0298543  0.02880013 0.02988401 0.04083689 0.04464587\n",
            "  0.04075521 0.02997141 0.0289405  0.02998647]]\n",
            "loss =  3.1041271023558274\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n",
            "[[0.02549301 0.0224977  0.02555667 0.04872487 0.06372452 0.04844839\n",
            "  0.02633258 0.0237451  0.02642494 0.02530625]\n",
            " [0.02222026 0.02536798 0.02547854 0.02246284 0.0255178  0.0258558\n",
            "  0.02304788 0.02594441 0.04855216 0.06334397]\n",
            " [0.04827528 0.0257024  0.02282697 0.02576121 0.04813719 0.0625352\n",
            "  0.04791231 0.02586079 0.02303813 0.02590486]]\n",
            "loss =  2.761462391710863\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n",
            "[[0.01251403 0.00792252 0.01259492 0.05758113 0.14381537 0.05681523\n",
            "  0.013396   0.00904343 0.01351335 0.01228163]\n",
            " [0.0076286  0.01236353 0.01245447 0.00782543 0.01251795 0.01286966\n",
            "  0.00836869 0.01297127 0.0573936  0.14280784]\n",
            " [0.05662204 0.01267481 0.00813706 0.01275476 0.05617896 0.13739268\n",
            "  0.05551198 0.01283874 0.00830923 0.01290107]]\n",
            "loss =  1.9567974778894304\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n",
            "[[1.29920494e-05 1.00000000e-06 1.33034455e-05 2.55616263e-03\n",
            "  3.43549232e-01 2.43502944e-03 1.60717283e-05 1.62368788e-06\n",
            "  1.65664245e-05 1.21205681e-05]\n",
            " [1.00000000e-06 1.24188966e-05 1.26230951e-05 1.00000000e-06\n",
            "  1.28882794e-05 1.40027781e-05 1.17172638e-06 1.44409716e-05\n",
            "  2.56135938e-03 3.48178833e-01]\n",
            " [2.44388103e-03 1.32672841e-05 1.02868711e-06 1.35942670e-05\n",
            "  2.37992499e-03 2.93414656e-01 2.28111656e-03 1.38151990e-05\n",
            "  1.11304887e-06 1.41095323e-05]]\n",
            "loss =  1.1165441193011645\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n"
          ]
        }
      ],
      "source": [
        "x = X_val[0]\n",
        "\n",
        "shrink = x.shape[1]//32\n",
        "batch_size = x.shape[0]\n",
        "print('shrink = ', shrink, 'batch_size = ', batch_size)\n",
        "\n",
        "model = vgg16(num_classes=10, shrink=shrink)\n",
        "params = sp_prop(model)\n",
        "#print(params)\n",
        "params.reverse()\n",
        "opt = adabound(params, lr=1e-3, betas=(0.9, 0.999), final_lr=7.5e-3, gamma=1e-5,\n",
        "                 eps=1e-8, weight_decay=0, amsbound=False)\n",
        "\n",
        "y = Y_val[2]\n",
        "print(y.reshape(y.shape[1], y.shape[0]))\n",
        "\n",
        "running_loss = 0\n",
        "Layers = sp_prop(model)\n",
        "num_epoch = 10\n",
        "\n",
        "for i in range(1, num_epoch + 1):\n",
        "\n",
        "  y_true, y_preds, TR, PR = [], [], [], []\n",
        "  running_loss = 0\n",
        "  opt.initialize_state(params)\n",
        "\n",
        "  for x, y in zip(X_val[2:3], Y_val[2:3]):\n",
        "\n",
        "    out = model.forward(x, batch_size)\n",
        "    loss = model.lnn3.compute_cost(out, y)\n",
        "    running_loss += loss\n",
        "    grads = model.backward(Layers[1:], batch_size)\n",
        "    opt.step(i)\n",
        "\n",
        "    out, y = out.reshape(out.shape[1], out.shape[0]), y.reshape(y.shape[1], y.shape[0])\n",
        "    print(out)\n",
        "    y_preds.extend(out)\n",
        "    y_true.extend(y)\n",
        "\n",
        "    PR.extend(np.argmax(out, axis=1))\n",
        "    TR.extend(np.argmax(y, axis=1))\n",
        "\n",
        "  \n",
        "  \n",
        "  y_true = np.array(y_true, dtype=np.int16)\n",
        "  y_preds = np.array(y_preds, dtype=np.int16)\n",
        "\n",
        "  print('loss = ', running_loss)\n",
        "  print('f1_macro = ', f1_score(TR, PR, average='macro'))\n",
        "  print('accuracy = ', accuracy_score(TR, PR))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J5HnPpaYWL-N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}