{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9EQof0pO7PSe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import h5py\n",
        "import scipy\n",
        "from sklearn.metrics import f1_score   \n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy import special\n",
        "from matplotlib.pyplot import imshow\n",
        "import cv2\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import keras\n",
        "import gc\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as k\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a1gmDarkp2KQ"
      },
      "outputs": [],
      "source": [
        "class adabound():\n",
        "\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), final_lr=0.1, gamma=1e-3,\n",
        "                 eps=1e-8, weight_decay=0, amsbound=False):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "        if not 0.0 <= final_lr:\n",
        "            raise ValueError(\"Invalid final learning rate: {}\".format(final_lr))\n",
        "        if not 0.0 <= gamma < 1.0:\n",
        "            raise ValueError(\"Invalid gamma parameter: {}\".format(gamma))\n",
        "\n",
        "        self.defaults = dict(lr=lr, betas=betas, final_lr=final_lr, gamma=gamma, eps=eps,\n",
        "                        weight_decay=weight_decay, amsbound=amsbound)\n",
        "        \n",
        "        self.param_groups = []\n",
        "\n",
        "        self.param_groups.append(dict(params=params, lr=lr, betas=betas, final_lr=final_lr, \n",
        "                                      gamma=gamma, eps=eps, weight_decay=weight_decay, amsbound=amsbound))\n",
        "\n",
        "        self.base_lrs = list(map(lambda group: group['lr'], self.param_groups))\n",
        "\n",
        "\n",
        "    def initialize_state(self, parameters):\n",
        "\n",
        "        L = len(parameters) # number of layers in the neural networks\n",
        "        self.m = {}\n",
        "        self.v = {}\n",
        "\n",
        "        for l in range(L):\n",
        "\n",
        "            \n",
        "\n",
        "            self.m[\"dw\" + str(l + 1)] = np.zeros_like(parameters[l].weight)\n",
        "            self.m[\"db\" + str(l + 1)] = np.zeros_like(parameters[l].bias)\n",
        "\n",
        "            self.v[\"dw\" + str(l+1)] = np.zeros_like(parameters[l].weight)\n",
        "            self.v[\"db\" + str(l+1)] = np.zeros_like(parameters[l].bias)\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "    def step(self, state=1):\n",
        "\n",
        "        for group, base_lr in zip(self.param_groups, self.base_lrs):\n",
        "            for p, l in zip(group['params'], range(len(group['params']))):\n",
        "                if p.grads is None:\n",
        "                    continue\n",
        "                grad = p.grads\n",
        "                \n",
        "                # State initialization\n",
        "                beta1, beta2 = group['betas']\n",
        "                if state == 1:\n",
        "                  self.initialize_state(self.param_groups[0]['params'])\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                self.m[\"dw\" + str(l + 1)] = beta1 * self.m[\"dw\" + str(l + 1)] + (1 - beta1) * grad['dw']\n",
        "                self.m[\"db\" + str(l + 1)] = beta1 * self.m[\"db\" + str(l + 1)] + (1 - beta1) * grad['db']\n",
        "\n",
        "                self.v[\"dw\" + str(l + 1)] = beta2 * self.v[\"dw\" + str(l + 1)] + (1 - beta2) * np.power(grad['dw'], 2)\n",
        "                self.v[\"db\" + str(l + 1)] = beta2 * self.v[\"db\" + str(l + 1)] + (1 - beta2) * np.power(grad['db'], 2)\n",
        "\n",
        "                \n",
        "                denom_w = np.sqrt(self.v[\"dw\" + str(l + 1)]) + group['eps']\n",
        "                denom_b = np.sqrt(self.v[\"db\" + str(l + 1)]) + group['eps']\n",
        "\n",
        "                bias_correction1 = 1 - beta1 ** state\n",
        "                bias_correction2 = 1 - beta2 ** state\n",
        "                step_size = group['lr'] * np.sqrt(bias_correction2)/ bias_correction1\n",
        "\n",
        "                final_lr = group['final_lr'] * group['lr'] / base_lr\n",
        "                lower_bound = final_lr * (1 - 1 / (group['gamma'] * state + 1))\n",
        "                upper_bound = final_lr * (1 + 1 / (group['gamma'] * state + group['eps']))\n",
        "\n",
        "                step_size_w = np.full_like(denom_w, step_size)\n",
        "                step_size_b = np.full_like(denom_b, step_size)\n",
        "\n",
        "                step_size_w = np.clip(step_size_w / denom_w, lower_bound, upper_bound) * self.m[\"dw\" + str(l + 1)] \n",
        "                step_size_b = np.clip(step_size_b / denom_b, lower_bound, upper_bound) * self.m[\"db\" + str(l + 1)]\n",
        "\n",
        "#               update parameters\n",
        "                p.weight -= step_size_w\n",
        "                p.bias -= step_size_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NplMU8P3p9ZV"
      },
      "outputs": [],
      "source": [
        "class adam():\n",
        "\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, amsbound=False):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "\n",
        "        self.defaults = dict(lr=lr, betas=betas, eps=eps,\n",
        "                        weight_decay=weight_decay, amsbound=amsbound)\n",
        "        \n",
        "        self.param_groups = []\n",
        "\n",
        "        self.param_groups.append(dict(params=params, lr=lr, betas=betas,eps=eps, weight_decay=weight_decay, amsbound=amsbound))\n",
        "\n",
        "        self.base_lrs = list(map(lambda group: group['lr'], self.param_groups))\n",
        "\n",
        "\n",
        "    def initialize_state(self, parameters):\n",
        "\n",
        "        L = len(parameters) # number of layers in the neural networks\n",
        "        self.v = {}\n",
        "        self.s = {}\n",
        "\n",
        "        for l in range(L):\n",
        "\n",
        "            \n",
        "\n",
        "            self.v[\"dw\" + str(l + 1)] = np.zeros_like(parameters[l].weight)\n",
        "            self.v[\"db\" + str(l + 1)] = np.zeros_like(parameters[l].bias)\n",
        "\n",
        "            self.s[\"dw\" + str(l+1)] = np.zeros_like(parameters[l].weight)\n",
        "            self.s[\"db\" + str(l+1)] = np.zeros_like(parameters[l].bias)\n",
        "\n",
        "    \n",
        "    def step(self, state=0):\n",
        "        v_corrected = {}                         # Initializing first moment estimate, python dictionary\n",
        "        s_corrected = {}\n",
        "\n",
        "        for group, base_lr in zip(self.param_groups, self.base_lrs):\n",
        "            for p, l in zip(group['params'], range(len(group['params']))):\n",
        "                if p.grads is None:\n",
        "                    continue\n",
        "                grad = p.grads\n",
        "                \n",
        "                # State initialization\n",
        "                beta1, beta2 = group['betas']\n",
        "                if state == 0:\n",
        "                  self.initialize_state(self.param_groups[0]['params'])\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                self.v[\"dw\" + str(l + 1)] = beta1 * self.v[\"dw\" + str(l + 1)] + (1 - beta1) * grad['dw']\n",
        "                self.v[\"db\" + str(l + 1)] = beta1 * self.v[\"db\" + str(l + 1)] + (1 - beta1) * grad['db']\n",
        "\n",
        "                v_corrected[\"dw\" + str(l + 1)] = self.v[\"dw\" + str(l + 1)] / (1 - np.power(beta1, state+1)+ group['eps'])\n",
        "                v_corrected[\"db\" + str(l + 1)] = self.v[\"db\" + str(l + 1)] / (1 - np.power(beta1, state+1)+ group['eps'])\n",
        "\n",
        "                self.s[\"dw\" + str(l + 1)] = beta2 * self.s[\"dw\" + str(l + 1)] + (1 - beta2) * np.power(grad['dw'], 2)\n",
        "                self.s[\"db\" + str(l + 1)] = beta2 * self.s[\"db\" + str(l + 1)] + (1 - beta2) * np.power(grad['db'], 2)\n",
        "\n",
        "                s_corrected[\"dw\" + str(l + 1)] = self.s[\"dw\" + str(l + 1)] / (1 - np.power(beta2, state+1) + group['eps'])\n",
        "                s_corrected[\"db\" + str(l + 1)] = self.s[\"db\" + str(l + 1)] / (1 - np.power(beta2, state+1) + group['eps'])\n",
        "\n",
        "#               update parameters\n",
        "                p.weight = p.weight - group['lr'] * v_corrected[\"dw\" + str(l + 1)] / np.sqrt(s_corrected[\"dw\" + str(l + 1)] + group['eps'])\n",
        "                p.bias = p.bias - group['lr'] * v_corrected[\"db\" + str(l + 1)] / np.sqrt(s_corrected[\"db\" + str(l + 1)] + group['eps'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-C5VYPMWjlzN"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "def reluDerivative(x):\n",
        "  \n",
        "    x[x<=0] = 0\n",
        "    x[x>0] = 1\n",
        "    return x\n",
        "\n",
        "def zero_pad(x, pad):\n",
        "  \"\"\"\n",
        "  Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
        "  as illustrated in Figure 1.\n",
        "    \n",
        "  Argument:\n",
        "  x -- python numpy array of shape (m, n_h, n_w, n_c) representing a batch of m images\n",
        "  pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
        "    \n",
        "  Returns:\n",
        "  X_pad -- padded image of shape (m, n_h + 2*pad, n_w + 2*pad, n_c)\n",
        "  \"\"\"\n",
        "\n",
        "  x_pad = np.pad(x, ((0, 0), (pad, pad), (pad, pad), (0,0)), mode=\"constant\", constant_values=(0, 0))\n",
        "\n",
        "  return x_pad"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getwindows(input, output_size, kernel_size, padding=1, stride=1, dilate=0):\n",
        "\n",
        "    \"\"\"\n",
        "    This function takes in an input of (b, h, w, c) and outputs of size (b, new_h, new_w, c, kernel_size, kernel_size) \n",
        "    The vector (b, new_h, new_w, c, kernel_size, kernel_size) is hard to visualize, but it is like as a batch of images where every \n",
        "    pixel in the image has an associated kernel_stridexkernel_stride window looking at it. This is useful when we combine these windowed \n",
        "    inputs with our layer weights. Dilation is necessary in this function, typically only in the backward pass of the convolution layer. \n",
        "    Dilating is useful here when the forward pass uses a convolution stride greater than 1. If that stride results in the output matrix\n",
        "    being smaller than the input, then in the backwards pass we need to dilate our gradient to increase its size to match the input matrix.\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    working_input = input\n",
        "    # Unpacking padding\n",
        "    working_pad = padding\n",
        "\n",
        "    # pad the input if necessary\n",
        "    if working_pad != 0:\n",
        "        working_input = zero_pad(working_input, padding)\n",
        "\n",
        "    # Dilate the input if necessary\n",
        "    if dilate != 0:\n",
        "        working_input = np.insert(working_input, range(1, input.shape[1]), 0.5, axis=1)\n",
        "        working_input = np.insert(working_input, range(1, input.shape[2]), -0.5, axis=2)\n",
        "\n",
        "    # Recieving dimenshions for output matrix calculation\n",
        "    b, out_h, out_w, in_c = output_size\n",
        "    b, _, _, out_c = input.shape\n",
        "    # Recieving bytes -  The strides of an array tell us how many bytes we have to skip in memory to move to the next position along a certain axis\n",
        "    batch_str, kern_h_str, kern_w_str, channel_str = working_input.strides\n",
        "\n",
        "    # Forming matrix with shape (b, new_h, new_w, c, kernel_size, kernel_size)\n",
        "    return np.lib.stride_tricks.as_strided(\n",
        "        working_input,\n",
        "        (b, out_h, out_w, out_c, kernel_size, kernel_size),\n",
        "        (batch_str, stride * kern_h_str, stride * kern_w_str, channel_str, kern_h_str, kern_w_str)\n",
        "    )"
      ],
      "metadata": {
        "id": "V3g3DezU4nTK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_frfh2Pi1O9T"
      },
      "outputs": [],
      "source": [
        "\n",
        "class conv2d:\n",
        "    \"\"\"\n",
        "    An implementation of the convolutional layer. We convolve the input with out_channels different filters\n",
        "    and each filter spans all channels in the input.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=0, pooling=False):\n",
        "        \"\"\"\n",
        "        param in_channels: the number of channels of the input data\n",
        "        param out_channels: the number of channels of the output(aka the number of filters applied in the layer)\n",
        "        param kernel_size: the specified size of the kernel(both height and width)\n",
        "        param stride: the stride of convolution\n",
        "        param padding: the size of padding. Pad zeros to the input with padding size.\n",
        "        \"\"\"\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.cache = None\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        self.weight = 7.5e-3 * np.random.randn(self.kernel_size, self.kernel_size, self.in_channels, self.out_channels)\n",
        "        self.bias = np.zeros((1, 1, 1, self.out_channels))\n",
        "\n",
        "    def conv_forward(self, x, activation='relu'):\n",
        "        \"\"\"\n",
        "        The forward pass of convolution\n",
        "        param x: input data of shape (m, n_h_prev, n_w_prev, n_c_prev)\n",
        "        return: output data of shape (m, n_h, n_w, n_c) where H' and W' are determined by the convolution\n",
        "                 parameters.\n",
        "        \"\"\"\n",
        "\n",
        "        # Unpacking the dimensions for later forming of new conv map shape and retrieving weights\n",
        "        a_prev = x\n",
        "        m, n_h_prev, n_w_prev, n_c_prev = x.shape\n",
        "        w = self.weight\n",
        "        b = self.bias\n",
        "        f, f, n_c_prev, n_c = w.shape\n",
        "\n",
        "        # retrieving stride and padding\n",
        "        stride = self.stride\n",
        "        pad = self.padding\n",
        "\n",
        "        # The calculations of new shape dimensions\n",
        "        n_h = int((n_h_prev + 2*pad - f)/stride) + 1\n",
        "        n_w = int((n_w_prev + 2*pad - f)/stride) + 1\n",
        "\n",
        "        # The squezzing by 2 times of new shape dimensions if there is a pooling\n",
        "        if self.pooling:\n",
        "          n_h = int(n_h/2)\n",
        "          n_w = int(n_w/2)\n",
        "\n",
        "        # Get windows from x with shape (b, h, w, i, k, l)\n",
        "        # where b = m - batch_size, h = n_h, w = n_w, i = self.in_channels, k = self.kernel_size, l = self.kernel_size\n",
        "        windows = getwindows(x, (m, n_h, n_w, n_c), self.kernel_size, self.padding, self.stride, dilate=0)\n",
        "        self.windows = windows\n",
        "       \n",
        "        # Matrix windows production with weight\n",
        "        out = np.einsum('bhwikl,klio->bhwo', windows, self.weight)\n",
        "\n",
        "\n",
        "        # add bias to out\n",
        "        out += self.bias\n",
        "        self.cache_activation = out\n",
        "\n",
        "        out = relu(out)\n",
        "        \n",
        "        # Making sure your output shape is correct\n",
        "        assert(out.shape == (m, n_h, n_w, n_c))\n",
        "\n",
        "        self.cache = (a_prev, windows)\n",
        "        \n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "\n",
        "        \"\"\"\n",
        "        The backward pass of convolution\n",
        "        param dout: upstream gradients\n",
        "        return: da_prev, dw, and db relative to this module\n",
        "        \"\"\"\n",
        "\n",
        "        # Unpacking the dimensions and retrieving weights\n",
        "        m = dout.shape[0]\n",
        "        stride = self.stride\n",
        "        padding = self.padding\n",
        "        w = self.weight\n",
        "        b = self.bias\n",
        "\n",
        "        # Calculation of derivetive for computing the dw\n",
        "        dout = reluDerivative(self.cache_activation) * dout\n",
        "\n",
        "        # Unpacking cache\n",
        "        (a_prev, windows) = self.cache\n",
        "\n",
        "        # Get windows from a_prev  with shape (b, h, w, o, k, l)\n",
        "        # where b = m - batch_size, h = n_h, w = n_w, o = self.output_channels, k = self.kernel_size, l = self.kernel_size\n",
        "        dout_windows = getwindows(dout, a_prev.shape, self.kernel_size, padding=padding, stride=1, dilate=0)\n",
        "\n",
        "        self.dout_windows = dout_windows\n",
        "        # Rotate the first and the second dimenshions counterclockwise 90 degrees 2 times\n",
        "        rot_kern = np.rot90(self.weight, 2, axes=(0, 1))\n",
        "\n",
        "        # Calculation db and matrix production between windows and derivetive(dout) weight\n",
        "        db = np.sum(dout, axis=(0, 1, 2))\n",
        "        dw = np.einsum('bhwikl,bhwo->klio', windows, dout)\n",
        "        # Calculation matrix production(derivative for the next backpropagation iteration) between dout_windows and rot_kern\n",
        "        da_prev = np.einsum('bhwokl,klio->bhwi', dout_windows, rot_kern)         \n",
        "        \n",
        "        # Calculate mean over m examples\n",
        "        dw /= m \n",
        "        db /= m\n",
        "\n",
        "        grads = dict(da_prev=da_prev, dw=dw, db=db)\n",
        "        self.grads = grads\n",
        "        return grads\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kLPqHj3Pnlqb"
      },
      "outputs": [],
      "source": [
        "class linear():   \n",
        "\n",
        "  def __init__(self, in_n, out_n, activation='relu'):\n",
        "\n",
        "    self.in_n = in_n\n",
        "    self.out_n = out_n\n",
        "    self.activation = activation\n",
        "    self.eps = 0.000001\n",
        "    self.initialize_parameters_deep([in_n, out_n])\n",
        "\n",
        "  def initialize_parameters_deep(self, layer_dims):\n",
        "  \n",
        "    \n",
        "    L = len(layer_dims)\n",
        "\n",
        "    for l in range(1, L):\n",
        "      self.weight = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
        "      self.bias = np.zeros((layer_dims[l], 1))\n",
        "\n",
        "\n",
        "  def linear_forward(self, a, w, b):\n",
        "\n",
        "    z = np.dot(w, a) + b\n",
        "    cache = a, w, b\n",
        "\n",
        "    return z, cache\n",
        "\n",
        "  def linear_activation_forward(self, a_prev, w, b, activation):\n",
        "\n",
        "    if activation == \"relu\":\n",
        "      z, linear_cache = self.linear_forward(a_prev, w, b)\n",
        "      a, activation_cache = self.relu(z)\n",
        "\n",
        "    if activation == \"sigmoid\":\n",
        "      z, linear_cache = self.linear_forward(a_prev, w, b)\n",
        "      a, activation_cache = self.sigmoid(z)\n",
        "\n",
        "    if activation =='softmax':\n",
        "      z, linear_cache = self.linear_forward(a_prev, w, b)\n",
        "      a, activation_cache = self.softmax(z)\n",
        "\n",
        "    cache = (linear_cache, activation_cache)\n",
        "    return a, cache\n",
        "\n",
        "  def l_linear_forward(self, x):\n",
        "\n",
        "    a = x\n",
        "    self.caches = []\n",
        "    \n",
        "    \n",
        "\n",
        "    AL, cache = self.linear_activation_forward(a, self.weight, self.bias, activation=self.activation)\n",
        "    self.caches.append(cache)\n",
        "\n",
        "    return AL\n",
        "\n",
        "  def compute_cost(self, AL, Y):\n",
        "    \n",
        "    AL = (AL==0) * self.eps + AL\n",
        "    Y = Y.reshape(AL.shape)\n",
        "    loss=-np.sum(Y*np.log(AL))\n",
        "    self.dAL = AL - Y\n",
        "\n",
        "    return loss/float(AL.shape[1])\n",
        "    \n",
        "\n",
        "  def linear_backward(self, dz, cache):\n",
        "\n",
        "    a_prev, w, b = cache\n",
        "    m = a_prev.shape[1]\n",
        "    dw = 1/m * np.dot(dz, a_prev.T)\n",
        "    db = 1/m * np.sum(dz, axis = 1, keepdims =True)\n",
        "    dA_prev = np.dot(w.T, dz)\n",
        "\n",
        "    return dA_prev, dw, db\n",
        "\n",
        "  def linear_activation_backward(self, da, cache, activation):\n",
        "\n",
        "    linear_cache, activation_cache = cache\n",
        "\n",
        "    if self.activation == \"relu\":\n",
        "      dz = self.relu_backward(da, activation_cache)\n",
        "      da_prev, dw, db = self.linear_backward(dz, linear_cache)\n",
        "\n",
        "    if self.activation == \"sigmoid\":\n",
        "      dz = self.sigmoid_backward(da, activation_cache)\n",
        "      da_prev, dw, db = self.linear_backward(dz, linear_cache)\n",
        "\n",
        "    if self.activation == \"softmax\":\n",
        "      dz = da\n",
        "      da_prev, dw, db = self.linear_backward(dz, linear_cache)\n",
        "\n",
        "    return da_prev, dw, db\n",
        "\n",
        "  def backward(self, da_prev=0.5):\n",
        "\n",
        "    grads = {}\n",
        "    L = len(self.caches) \n",
        "    if self.activation == 'softmax':\n",
        "      dAL = self.dAL\n",
        "    else:\n",
        "      dAL = da_prev\n",
        "\n",
        "    current_cache = self.linear_activation_backward(dAL, self.caches[L-1], activation=self.activation)\n",
        "    d_aprev_temp, dw_temp, db_temp = current_cache\n",
        "    grads[\"da_prev\"] = d_aprev_temp\n",
        "    grads[\"dw\"] = dw_temp\n",
        "    grads[\"db\"] = db_temp\n",
        "\n",
        "\n",
        "    self.grads = grads\n",
        "    return grads\n",
        "\n",
        "          \n",
        "    return parameters\n",
        "\n",
        "  def softmax(self, z):\n",
        "\n",
        "    a = special.softmax(z)\n",
        "    a = np.clip(a, self.eps, 1)\n",
        "\n",
        "    return a, z\n",
        "\n",
        "\n",
        "  def relu(self, z):\n",
        "\n",
        "    a = z * (z > 0)\n",
        "\n",
        "    return a, z\n",
        "\n",
        "  def relu_backward(self, da, z):\n",
        "\n",
        "    g = 1 * (z > 0)\n",
        "    dz = np.multiply(g, da)\n",
        "\n",
        "    return dz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KrteA5VRPPL0"
      },
      "outputs": [],
      "source": [
        "class vgg16():\n",
        "    def __init__(self, num_classes=10, shrink=7):\n",
        "\n",
        "        self.layer1 = conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer2 = conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, pooling=True)\n",
        "        self.layer3 = conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer4 = conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, pooling=True)\n",
        "        self.layer5 = conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer6 = conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer7 = conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, pooling=True)\n",
        "        self.layer8 = conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer9 = conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer10 = conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1, pooling=True)\n",
        "        self.layer11 = conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer12 = conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer13 = conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1, pooling=True)\n",
        "        self.lnn1 = linear(shrink*shrink*512, 4096)\n",
        "        self.lnn2 = linear(4096, 4096)\n",
        "        self.lnn3 = linear(4096, num_classes, activation='softmax')\n",
        "\n",
        "        \n",
        "    def forward(self, x, batch_size=1):\n",
        "        out = self.layer1.conv_forward(x)\n",
        "        out = self.layer2.conv_forward(out)\n",
        "        #print(out.shape)\n",
        "        out = self.layer3.conv_forward(out)\n",
        "        out = self.layer4.conv_forward(out)\n",
        "        #print(out.shape)\n",
        "        out = self.layer5.conv_forward(out)\n",
        "        out = self.layer6.conv_forward(out)\n",
        "        out = self.layer7.conv_forward(out)\n",
        "       # print(out.shape)\n",
        "        out = self.layer8.conv_forward(out)\n",
        "        out = self.layer9.conv_forward(out)\n",
        "        out = self.layer10.conv_forward(out)\n",
        "       # print(out.shape)\n",
        "        out = self.layer11.conv_forward(out)\n",
        "        out = self.layer12.conv_forward(out)\n",
        "        out = self.layer13.conv_forward(out)\n",
        "       # print(out.shape)\n",
        "        out = out.reshape(-1, batch_size)\n",
        "        #print(out.shape)\n",
        "        out = self.lnn1.l_linear_forward(out)\n",
        "        out = self.lnn2.l_linear_forward(out)\n",
        "        out = self.lnn3.l_linear_forward(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, layers, batch_size=1):\n",
        "\n",
        "      self.GR = []\n",
        "      grads = self.lnn3.backward()\n",
        "      self.GR.append(grads)\n",
        "\n",
        "      for l in layers[0:2]: \n",
        "        grads = l.backward(grads['da_prev'])\n",
        "        self.GR.append(grads)\n",
        "      a_prev = self.layer13.cache[0]\n",
        "      dim = int(a_prev.shape[1] / 2)\n",
        "      grads['da_prev'] = grads['da_prev'].reshape(batch_size, dim, dim, 512)\n",
        "      for l in layers[2:]: \n",
        "        grads = l.backward(grads['da_prev'])\n",
        "        self.GR.append(grads)\n",
        "\n",
        "      GR = self.GR\n",
        "\n",
        "      return GR\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "v6v76z7_v0z3"
      },
      "outputs": [],
      "source": [
        "def sp_prop(model):\n",
        "\n",
        "  spisok = []\n",
        "  spisok_l = []\n",
        "\n",
        "  for l in model.__dict__.keys():\n",
        "    spisok.append(model.__dict__[l])\n",
        "\n",
        "  for l in reversed(spisok):\n",
        "    spisok_l.append(l)\n",
        "  \n",
        "  return spisok_l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "z3FkNsC2VD_m"
      },
      "outputs": [],
      "source": [
        "x= np.random.randn(2, 32, 32, 1)\n",
        "batch_size = x.shape[0]\n",
        "model = vgg16(num_classes=10, shrink=x.shape[1]//32)\n",
        "params = sp_prop(model)\n",
        "params.reverse()\n",
        "opt = adabound(params=params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cC31IV-JJd5N"
      },
      "outputs": [],
      "source": [
        "AA = model.forward(x, batch_size)\n",
        "loss = model.lnn3.compute_cost(AA, np.array(np.eye(20)[1]).reshape(-1, 2))\n",
        "layers = sp_prop(model)\n",
        "grads = model.backward(layers[1:], x.shape[0])\n",
        "opt.step(state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnp7tmyzGqHO",
        "outputId": "132bd9f0-002c-4dfb-cdf8-41fb24eb6219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from matplotlib import pyplot\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "Ry1jRWmUn77L",
        "outputId": "c37090fd-392b-496d-c7ff-445a02d21d95"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "for i in range(3):  \n",
        "  pyplot.subplot(330 + 1 + i)\n",
        "  pyplot.imshow(x_train[i], cmap=pyplot.get_cmap('gray'))\n",
        "  pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "I4XCCuOgoNik"
      },
      "outputs": [],
      "source": [
        "# expand new axis, channel axis \n",
        "x_train, x_test = np.expand_dims(x_train, axis=-1), np.expand_dims(x_test, axis=-1)\n",
        "# it's always better to normalize \n",
        "x_train, x_test = x_train.astype('float32') / 255.0, x_test.astype('float32') / 255.0\n",
        "# resize the input shape , i.e. old shape: 28, new shape: 32\n",
        "x_train, x_test = tf.image.resize(x_train, [32,32]), tf.image.resize(x_test, [32,32]) # if we want to resize \n",
        "# one-hot \n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPZ5JBJdoQjv",
        "outputId": "58a58ed6-c8d6-42b4-ccc9-51dd882f51c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([60000, 32, 32, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beTfqCdYoTqJ",
        "outputId": "6fa19370-6ead-4e52-99e2-b13a3e2c08c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 32, 32, 1) (60000, 10)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pSCEVnmcoVkH"
      },
      "outputs": [],
      "source": [
        "# Batch_size\n",
        "X_train, Y_train, X_val, Y_val = [], [], [], []\n",
        "batch_size = 3\n",
        "for i in range(0, 60, batch_size):\n",
        "  start_idx, end_idx = i, i + batch_size\n",
        "  X_train.append(x_train[start_idx:end_idx])\n",
        "  Y_train.append(y_train[start_idx:end_idx].reshape(10, batch_size))\n",
        "\n",
        "for i in range(0, 10, batch_size):\n",
        "  start_idx, end_idx = i, i + batch_size\n",
        "  X_val.append(x_test[start_idx:end_idx])\n",
        "  Y_val.append(y_test[start_idx:end_idx].reshape(10, batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM6FcOE-o7Er",
        "outputId": "cf636c0e-028f-4f17-855b-93cc4b36d475"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3, 32, 32, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "X_val[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "V58v9Ze4tuz-"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "for i in range(10):\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNgRlu_G2R2j",
        "outputId": "1910fed3-0374-4177-eccb-7cb6f7ffce8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shrink =  1 batch_size =  3\n",
            "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "[[0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
            "  0.03333333 0.03333333 0.03333333 0.03333333]\n",
            " [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
            "  0.03333333 0.03333333 0.03333333 0.03333333]\n",
            " [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
            "  0.03333333 0.03333333 0.03333333 0.03333333]]\n",
            "loss =  3.4011973816621643\n",
            "f1_macro =  0.0\n",
            "accuracy =  0.0\n",
            "[[0.03324221 0.03324359 0.03324151 0.03355597 0.03355882 0.03355608\n",
            "  0.03323048 0.0332312  0.03323006 0.03326608]\n",
            " [0.03326678 0.03326582 0.03324812 0.03324793 0.03324587 0.03321208\n",
            "  0.03321336 0.03321202 0.03351328 0.03351522]\n",
            " [0.03351393 0.03327757 0.03327943 0.03327696 0.03353266 0.0335373\n",
            "  0.03353347 0.03325004 0.03325152 0.03325065]]\n",
            "loss =  3.3951027643174645\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n",
            "[[0.03304188 0.03303894 0.03303925 0.03401269 0.03403244 0.03401254\n",
            "  0.03302814 0.03302711 0.03302859 0.03311098]\n",
            " [0.03310977 0.03310872 0.03307233 0.03307205 0.03306958 0.03299869\n",
            "  0.03299711 0.03299897 0.03394154 0.03395814]\n",
            " [0.03394248 0.03308624 0.03308702 0.03308611 0.03398527 0.03400404\n",
            "  0.03398603 0.03304126 0.03304176 0.03304032]]\n",
            "loss =  3.381447879440341\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n",
            "[[0.03277228 0.03275566 0.03276801 0.03465311 0.03472108 0.03465246\n",
            "  0.03274896 0.03273698 0.03275037 0.03286719]\n",
            " [0.03285482 0.03286463 0.03280608 0.03279522 0.03280336 0.03270376\n",
            "  0.03269047 0.03270565 0.03454245 0.03460422]\n",
            " [0.03454454 0.03284865 0.0328402  0.03284783 0.03459912 0.03466648\n",
            "  0.03460125 0.03275628 0.03274394 0.03275494]]\n",
            "loss =  3.3620566386831414\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n",
            "[[0.0323667  0.03229975 0.03236117 0.03560071 0.03582837 0.03560149\n",
            "  0.03234086 0.03227567 0.03234164 0.03250908]\n",
            " [0.03245297 0.03250361 0.03240857 0.03235148 0.03240329 0.0322666\n",
            "  0.03219758 0.03226995 0.03543706 0.03564381]\n",
            " [0.03544302 0.03248549 0.03243346 0.03248486 0.03551792 0.03573824\n",
            "  0.03552094 0.03232641 0.0322648  0.03232452]]\n",
            "loss =  3.3315763886163494\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n",
            "[[0.03173904 0.03150332 0.03172762 0.03705655 0.03779491 0.03705932\n",
            "  0.03170568 0.0314705  0.03170509 0.03194397]\n",
            " [0.03174188 0.03193611 0.03179481 0.03157432 0.03178225 0.03159294\n",
            "  0.03134212 0.03159619 0.03680332 0.03748704]\n",
            " [0.03681738 0.03191508 0.03171211 0.03191013 0.03693007 0.03764636\n",
            "  0.03694028 0.03167334 0.0314329  0.03166537]]\n",
            "loss =  3.2796199914315447\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n",
            "[[0.030659   0.02990314 0.0306397  0.03947674 0.04186669 0.03949561\n",
            "  0.03062358 0.02986547 0.03062126 0.03096827]\n",
            " [0.03029933 0.03095382 0.03074381 0.03001406 0.03072378 0.03045617\n",
            "  0.02965062 0.0304574  0.0390676  0.0412769 ]\n",
            " [0.03910009 0.03092126 0.03024307 0.03091185 0.03926684 0.04158549\n",
            "  0.03929492 0.0305683  0.02979265 0.03055258]]\n",
            "loss =  3.180240319182596\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n",
            "[[0.02844934 0.02625304 0.0284049  0.04394387 0.05220371 0.0440206\n",
            "  0.02841995 0.02620804 0.02839585 0.02891594]\n",
            " [0.02692441 0.02888149 0.02857495 0.02644189 0.02853851 0.02814286\n",
            "  0.02582609 0.02813533 0.0432368  0.05087187]\n",
            " [0.04333266 0.02882724 0.02681068 0.02880722 0.04358554 0.05156548\n",
            "  0.04367227 0.02830155 0.02604651 0.02826141]]\n",
            "loss =  2.9653164996750583\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n",
            "[[0.02225047 0.0170065  0.02217552 0.05200887 0.08853166 0.0522261\n",
            "  0.02224343 0.01696752 0.02219246 0.02295259]\n",
            " [0.01802886 0.02288883 0.02244299 0.01729785 0.02237707 0.02183382\n",
            "  0.01643013 0.02181999 0.05055422 0.08377402]\n",
            " [0.05079145 0.02279116 0.01782737 0.02275173 0.05128545 0.08630615\n",
            "  0.0515113  0.02204521 0.01670583 0.02198146]]\n",
            "loss =  2.4512939523332187\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n",
            "[[0.00756706 0.00313662 0.00752423 0.04281498 0.2191629  0.04301773\n",
            "  0.00757486 0.0031364  0.00756004 0.0080185 ]\n",
            " [0.00360702 0.00799149 0.00769242 0.00327427 0.00765927 0.00730646\n",
            "  0.00289969 0.00730654 0.04062267 0.19318047]\n",
            " [0.0408823  0.00792188 0.00351714 0.00790504 0.04176412 0.20713372\n",
            "  0.04198471 0.00742992 0.00300577 0.00740179]]\n",
            "loss =  1.5788203833904768\n",
            "f1_macro =  1.0\n",
            "accuracy =  1.0\n"
          ]
        }
      ],
      "source": [
        "x = X_val[0]\n",
        "\n",
        "shrink = x.shape[1]//32\n",
        "batch_size = x.shape[0]\n",
        "print('shrink = ', shrink, 'batch_size = ', batch_size)\n",
        "\n",
        "model = vgg16(num_classes=10, shrink=shrink)\n",
        "params = sp_prop(model)\n",
        "#print(params)\n",
        "params.reverse()\n",
        "opt = adabound(params, lr=1e-3, betas=(0.9, 0.999), final_lr=7.5e-3, gamma=1e-5,\n",
        "                 eps=1e-8, weight_decay=0, amsbound=False)\n",
        "\n",
        "y = Y_val[2]\n",
        "print(y.reshape(y.shape[1], y.shape[0]))\n",
        "\n",
        "running_loss = 0\n",
        "Layers = sp_prop(model)\n",
        "num_epoch = 10\n",
        "\n",
        "for i in range(1, num_epoch + 1):\n",
        "\n",
        "  y_true, y_preds, TR, PR = [], [], [], []\n",
        "  running_loss = 0\n",
        "  opt.initialize_state(params)\n",
        "\n",
        "  for x, y in zip(X_val[2:3], Y_val[2:3]):\n",
        "\n",
        "    out = model.forward(x, batch_size)\n",
        "    loss = model.lnn3.compute_cost(out, y)\n",
        "    running_loss += loss\n",
        "    grads = model.backward(Layers[1:], batch_size)\n",
        "    opt.step(i)\n",
        "\n",
        "    out, y = out.reshape(out.shape[1], out.shape[0]), y.reshape(y.shape[1], y.shape[0])\n",
        "    print(out)\n",
        "    y_preds.extend(out)\n",
        "    y_true.extend(y)\n",
        "\n",
        "    PR.extend(np.argmax(out, axis=1))\n",
        "    TR.extend(np.argmax(y, axis=1))\n",
        "\n",
        "  \n",
        "  \n",
        "  y_true = np.array(y_true, dtype=np.int16)\n",
        "  y_preds = np.array(y_preds, dtype=np.int16)\n",
        "\n",
        "  print('loss = ', running_loss)\n",
        "  print('f1_macro = ', f1_score(TR, PR, average='macro'))\n",
        "  print('accuracy = ', accuracy_score(TR, PR))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J5HnPpaYWL-N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}